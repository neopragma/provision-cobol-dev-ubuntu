<!DOCTYPE html>
<html>
<head>
<title>Cobol development environment</title>
<style>
h1, h2, h3, h4 {
	font-family: Verdana, Arial, Lucida Sans, sans-serif;	
	color: #036;
}
li {
	margin-top: 8px;
}
.box {
    border: 1px dashed black;
    background-color: #eee;
    padding-left: 8px;
}
.code {
    font-family: Courier New, monospaced;
    font-weight: bold;
}
.sidebar {
	font-family: Verdana, Arial, Lucida Sans, sans-serif;
	font-size: 90%;
	background-color: #eef;
	padding-left: 8px;
	padding-right: 8px;
	margin-left: 24px;
	margin-right: 24px;
}
</style>
</head>
<body>

<h1>Cobol development environment</h1>
<p>
This is an Ubuntu Linux VM configured with GNU Cobol. It has no database installed, and is not meant to emulate mainframe Cobol precisely. The purpose is to provide a basic working environment for Cobol development that doesn't require connectivity to a mainframe system. 
</p>

<h2>Build script for batch programs</h2>
<p>
The build script for batch programs is called <span class="code">cobuild</span>. It will be easier and quicker for you to read the source and run the script with different arguments than it would be to read a detailed description here. To see the usage help for the script, run  it with the <span class="code">--help</span> option:
</p>
<p>
<pre class="code box">
cobuild --help
</pre>
</p>
<p>
This produces output like the following:
</p>
<p align="center">
<img src="Documentation/images/cobuild-help.png" align="center" border="0"/>
</p>
<p>
In a nutshell, the <span class="code">cobuild</span> script does the following:
</p>
<p>
<ol>
<li>Compile the production code</li>
<li>Compile the test code</li>
<li>Run the unit tests</li>
<li>Run the integration tests</li>
<li>Move the executable to a target directory</li>
</ol>
</p>
<p>
If you have used Maven or Ant (or pretty much any build utility) on a Unix, Linux, or Windows platform, then you are familiar with the general sequence of steps. 
</p>
<p>
Here is the output produced by <span class="code">cobuild</span> when building one of the sample applications, the file converter (see <a href="https://github.com/neopragma/cobol-unit-test">https://github.com/neopragma/cobol-unit-test</a>):
</p>
<p align="center">
<img src="Documentation/images/cobuild-output.png" align="center" border="0"/>
</p>
<p>
This is the way we run <span class="code">cobuild</span> to build the sample program, <span class="code">convert.cbl</span>:
</p>
<p>
<pre class="code box">
cobuild -u convert-unit-tests -i ./integration-tests convert.cbl
</pre>
</p>
<p>
We tell <span class="code">cobuild</span> where to find our unit tests and integration tests, and we accept the default settings for all other options. When you explore the sample project you will see that <span class="code">convert-unit-tests</span> is a Cobol copybook and <span class="code">integration-tests</span> is a <span class="code">bash</span> shell script that prepares a couple of files, calls a test program written in Cobol, and checks the result.
</p>
<p>
This environment can be used to develop Cobol applications to be deployed on Unix, Linux, Windows, or zOS platforms. It can also be used as an off-platform development and unit test environment for supporting existing &quot;legacy&quot; Cobol programs. You can do much of the coding and testing work for these applications on this environment and then upload your code to the mainframe system, where you need only do end-to-end functional testing and system-level testing such as performance testing.
</p>


<

<h3>Automated integration tests (batch)</h3>
<p>
No modifications to the program under test are necessary to support integration testing, but the nature of the integration tests depends on just what the program does. For the file conversion example, <span class="code">projects/file-converter</span>, an integration test runs a few representative input records through the conversion program and compares the actual output file with a file containing the expected output. A generic program that compares the contents of two sequential input files is provided in the <span class="code">file-converter</span> project. You can use this program to prepare integration test scripts for any application program that has a similar function. For programs that do other sorts of processing, you will have to write a special integration test driver. 
</p>
<p>
The integration test run is set up and managed by a shell script. The build script takes the name of the integration test script as an argument and executes it at the appropriate point in the build process.
</p>

<h3>File Converter (projects/file-converter)</h3>
<p>
A common type of Cobol program still in use in corporate IT departments is a batch program that reads one or more input files, converts the records into a different format, and writes them to output files or databases. The file-converter project contains a simple file conversion program and demonstrates how we can write automated unit tests and integration tests for such a program. 
</p>

<h2>CICS programs</h2>

<h3>Automated unit tests using IBM tools</h3>
<p>
Dynamic Scripting is a feature of CICS that supports test-driven development of web applications targeted to the CICS environment (among other things). If your organization already has Dynamic Scripting installed, you can also use it to drive automated tests for legacy CICS applications written in any language. Refer to this IBM Redbook for more information: <a href="http://www.redbooks.ibm.com/redbooks/pdfs/sg247924.pdf">Introduction to CICS Dynamic Scripting</a>.
</p>
<p>
IBM's Rational Developer tools include a unit testing framework for zOS. It supports unit testing of application programs targeted to various IBM environments, including CICS among others. It is expensive, heavy, complicated, and requires a separate server running Red Hat Enterprise Linux or Suse Enterprise Linux. It is functional, but not something that would support a rapid development workflow that includes frequent local builds and continuous integration.
</p>

<h3>Automated unit tests the old-fashioned way</h3>
<p>
Most legacy CICS applications are CRUD apps &mdash; they perform <em>create</em>, <em>read</em>, <em>update</em>, and <em>delete</em> operations on some data store, controlled by a user interacting with the application through a terminal. Another common type of CICS application is a "pipeline" application that processes transactions by handing off a data structure through a chain of programs via XCTL commands. A listener task is triggered when an inbound request arrives via some communication mechanism (TCP/IP socket, IBM 3600 Pipeline LU, etc.) and it initiates the chain of programs.
</p>
<p>
For these types of applications, we can write test programs that exercise the logic in production programs and verify they produce the correct results. The "unit" in this case is not a single paragraph, but a single CICS application program. When well designed, the individual programs in a CICS application will be fairly small and each will have a single purpose, making them well suited to unit testing.
</p>
<p>
The basic pattern for a test case is to initialize a COMMAREA, LINK to the program under test, and then compare the contents of the COMMAREA with the expected results. (To test programs in isolation that normally are invoked via XCTL, we can LINK to them.) Finally, we append the test results to a file that accumulates results from all of our test programs. 
</p>
<p>
To enable this approach, the CICS application code has to be organized such that the "business logic" piece can be invoked via LINK without accessing any external resources; that is, without trying to interact with BMS, File Control, or any databases. Some legacy programs might have to be refactored and separated out into multiple programs &mdash; one that only maps data values to and from the screen area and issues BMS commands; one that encapsulates the "business logic," and one or more that interact with data stores. Once this is done, the test program can LINK to the "business logic" program without any side effects.
</p>
<p>
In addition, if we pass the names of any I/O interface programs in COMMAREA instead of hard-coding them, we have a quick-and-dirty "mocking" facility &mdash; we can prepare a fake I/O program that returns the values our test case requires, without the need to populate any real files or databases with test data.
</p>
<p>
The procedure we have described so far still involves running the tests in a live CICS region, which does not quite give us proper isolation for rapid turnaround of unit tests. To enable off-platform, isolated unit testing in a way that supports contemporary continuous integration work flows, we need to fake out the CICS runtime environment. In this sandbox environment, we accomplish this by using a custom-written EXEC CICS preprocessor that replaces CICS commands with calls to fake CICS modules. This sort of fake module is called a &quot;test double.&quot; Test doubles are commonly used to isolate the code under test from external runtime dependencies.
</p>

<h3>Automated integration &amp; acceptance tests using IBM or third-party tools</h3>
<p>
This type of test uses 3270 terminal emulation to execute a scripted sequence of "user" actions against a CICS application. This level of testing does require real files and databases to exist and to be populated with appropriate test data.
</p>
<p>
There is little value in rolling your own terminal emulator. We recommend identifying an appropriate product to support this kind of testing for your CICS applications. Some alternatives (not exhaustive):
</p>
<p>
<ul>
<li>The Dynamic Scripting features of CICS provide a toolset familiar to Java web application developers for the zOS CICS platform. If your organization has these features installed, you can write JUnit tests in Java to exercise legacy CICS Command Level application programs written in Cobol, PL/I, or Assembly language, as well as CICS-hosted webapps written in Java or PHP.</li>
<li>If you don't have access to Dynamic Scripting, you can roll your own CICS test harness that invokes programs using LINK and makes assertions about the contents of COMMAREA. This may require some refactoring of legacy programs that commingle BMS logic with "business" logic.</li>
<li>Cucumber acceptance testing framework. This solution requires Ruby, the te3270 Ruby gem, and any of the commercial 3270 emulators that te3270 supports. Due to the dependency on third-party commercial 3270 emulators, the Cucumber environment has to run on a Microsoft Windows system. Compared with mainframe-based commercial products like CA Verify and Hiperstation, this solution offers the flexibility to do acceptance test driven development (ATDD) in addition to conventional automated regression testing.</li>
<li>CA Verify for CICS. This is a mainframe-hosted commercial product that supports several types of automated testing for CICS applications. The vendor literature claims CA Verify supports &quot;unit testing,&quot; but that description appears to assume a relatively expansive definition of &quot;unit&quot; as compared with generally-accepted software development practices.</li>
<li>Compuware QA Hiperstation. This is a mainframe-hosted commercial product that supports automated regression and security testing for CICS as well as other mainframe-based transaction processing environments such as VTAM and TCP/IP.</li>
</ul>
</p>

<h3>Automated integration &amp; acceptance tests the old-fashioned way</h3>
<p>
It is straightforward to write integration tests and acceptance tests using the same approach as described above for unit tests of CICS program. The difference between an integration test and a unit test is the scope of the code under test; a unit test exercises a single interaction with a single CICS program, while an integration test exercises a series of interactions that may involve multiple CICS programs and that may access real external resources. The mechanics of writing such a test program are the same as for unit tests.
</p>
</body>
</html>
